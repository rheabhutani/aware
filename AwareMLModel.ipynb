{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 5000\n",
    "MAX_NUM_WORDS = 25000\n",
    "EMBEDDING_DIM = 300\n",
    "TEST_SPLIT = 0.2\n",
    "TEXT_DATA = 'dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text label\n",
      "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE\n",
      "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE\n",
      "2     U.S. Secretary of State John F. Kerry said Mon...  REAL\n",
      "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE\n",
      "4     It's primary day in New York and front-runners...  REAL\n",
      "...                                                 ...   ...\n",
      "6330  The State Department told the Republican Natio...  REAL\n",
      "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE\n",
      "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE\n",
      "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL\n",
      "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL\n",
      "\n",
      "[6335 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(TEXT_DATA)\n",
    "df.drop(labels=['id','title'], axis='columns', inplace=True)\n",
    "# only select stories with lengths gt 0 -- there are some texts with len = 0\n",
    "mask = list(df['text'].apply(lambda x: len(x) > 0))\n",
    "df = df[mask]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6335 texts.\n"
     ]
    }
   ],
   "source": [
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "print('Found %s texts.' %texts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98817 unique tokens.\n",
      "Shape of data tensor: (6335, 5000)\n",
      "Shape of label tensor: (6335,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "print(sequences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "data = pad_sequences(sequences, \n",
    "                     maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                     padding='pre', \n",
    "                     truncating='pre')\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text_data, test_text_data, train_labels, test_labels = train_test_split(data, \n",
    "                                                  labels.apply(lambda x: 0 if x == 'FAKE' else 1),\n",
    "                                                  test_size=TEST_SPLIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5000, 300)         7500300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4996, 128)         192128    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,709,069\n",
      "Trainable params: 7,709,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        # part 1: word and sequence processing\n",
    "        layers.Embedding(num_words,\n",
    "                         EMBEDDING_DIM, \n",
    "                         input_length=MAX_SEQUENCE_LENGTH,\n",
    "                         trainable=True),\n",
    "        layers.Conv1D(128, 5, activation='relu'),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "        # part 2: classification\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 5068 samples, validate on 1267 samples\n",
      "Epoch 1/6\n",
      "5068/5068 [==============================] - 124s 24ms/step - loss: 0.4661 - acc: 0.7820 - val_loss: 0.2522 - val_acc: 0.8998\n",
      "Epoch 2/6\n",
      "5068/5068 [==============================] - 123s 24ms/step - loss: 0.1295 - acc: 0.9584 - val_loss: 0.1215 - val_acc: 0.9487\n",
      "Epoch 3/6\n",
      "5068/5068 [==============================] - 125s 25ms/step - loss: 0.0385 - acc: 0.9917 - val_loss: 0.0935 - val_acc: 0.9613\n",
      "Epoch 4/6\n",
      "5068/5068 [==============================] - 126s 25ms/step - loss: 0.0078 - acc: 0.9996 - val_loss: 0.0904 - val_acc: 0.9597\n",
      "Epoch 5/6\n",
      "5068/5068 [==============================] - 125s 25ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9597\n",
      "Epoch 6/6\n",
      "5068/5068 [==============================] - 129s 25ms/step - loss: 1.8269e-04 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 0.9637\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_text_data, \n",
    "                    train_labels,\n",
    "                    batch_size=128,\n",
    "                    epochs=6,\n",
    "                    validation_data=(test_text_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    return np.rint(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    q = predict( np.array( [train_text_data[i],] )  )\n",
    "    print(q)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = \"\"\"U.S. Secretary of State John F. Kerry said Monday that he will stop in Paris later this week, amid criticism that no top American officials attended Sunday’s unity march against terrorism.\n",
    "\n",
    "Kerry said he expects to arrive in Paris Thursday evening, as he heads home after a week abroad. He said he will fly to France at the conclusion of a series of meetings scheduled for Thursday in Sofia, Bulgaria. He plans to meet the next day with Foreign Minister Laurent Fabius and President Francois Hollande, then return to Washington.\n",
    "\n",
    "The visit by Kerry, who has family and childhood ties to the country and speaks fluent French, could address some of the criticism that the United States snubbed France in its darkest hour in many years.\n",
    "\n",
    "The French press on Monday was filled with questions about why neither President Obama nor Kerry attended Sunday’s march, as about 40 leaders of other nations did. Obama was said to have stayed away because his own security needs can be taxing on a country, and Kerry had prior commitments.\n",
    "\n",
    "Among roughly 40 leaders who did attend was Israeli Prime Minister Benjamin Netanyahu, no stranger to intense security, who marched beside Hollande through the city streets. The highest ranking U.S. officials attending the march were Jane Hartley, the ambassador to France, and Victoria Nuland, the assistant secretary of state for European affairs. Attorney General Eric H. Holder Jr. was in Paris for meetings with law enforcement officials but did not participate in the march.\n",
    "\n",
    "Kerry spent Sunday at a business summit hosted by India’s prime minister, Narendra Modi. The United States is eager for India to relax stringent laws that function as barriers to foreign investment and hopes Modi’s government will act to open the huge Indian market for more American businesses.\n",
    "\n",
    "In a news conference, Kerry brushed aside criticism that the United States had not sent a more senior official to Paris as “quibbling a little bit.” He noted that many staffers of the American Embassy in Paris attended the march, including the ambassador. He said he had wanted to be present at the march himself but could not because of his prior commitments in India.\n",
    "\n",
    "“But that is why I am going there on the way home, to make it crystal clear how passionately we feel about the events that have taken place there,” he said.\n",
    "\n",
    "“And I don’t think the people of France have any doubts about America’s understanding of what happened, of our personal sense of loss and our deep commitment to the people of France in this moment of trauma.”\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. Secretary of State John F. Kerry said Monday that he will stop in Paris later this week, amid criticism that no top American officials attended Sunday’s unity march against terrorism.\\n\\nKerry said he expects to arrive in Paris Thursday evening, as he heads home after a week abroad. He said he will fly to France at the conclusion of a series of meetings scheduled for Thursday in Sofia, Bulgaria. He plans to meet the next day with Foreign Minister Laurent Fabius and President Francois Hollande, then return to Washington.\\n\\nThe visit by Kerry, who has family and childhood ties to the country and speaks fluent French, could address some of the criticism that the United States snubbed France in its darkest hour in many years.\\n\\nThe French press on Monday was filled with questions about why neither President Obama nor Kerry attended Sunday’s march, as about 40 leaders of other nations did. Obama was said to have stayed away because his own security needs can be taxing on a country, and Kerry had prior commitments.\\n\\nAmong roughly 40 leaders who did attend was Israeli Prime Minister Benjamin Netanyahu, no stranger to intense security, who marched beside Hollande through the city streets. The highest ranking U.S. officials attending the march were Jane Hartley, the ambassador to France, and Victoria Nuland, the assistant secretary of state for European affairs. Attorney General Eric H. Holder Jr. was in Paris for meetings with law enforcement officials but did not participate in the march.\\n\\nKerry spent Sunday at a business summit hosted by India’s prime minister, Narendra Modi. The United States is eager for India to relax stringent laws that function as barriers to foreign investment and hopes Modi’s government will act to open the huge Indian market for more American businesses.\\n\\nIn a news conference, Kerry brushed aside criticism that the United States had not sent a more senior official to Paris as “quibbling a little bit.” He noted that many staffers of the American Embassy in Paris attended the march, including the ambassador. He said he had wanted to be present at the march himself but could not because of his prior commitments in India.\\n\\n“But that is why I am going there on the way home, to make it crystal clear how passionately we feel about the events that have taken place there,” he said.\\n\\n“And I don’t think the people of France have any doubts about America’s understanding of what happened, of our personal sense of loss and our deep commitment to the people of France in this moment of trauma.”'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = \"\"\"Google Pinterest Digg Linkedin Reddit Stumbleupon Print Delicious Pocket Tumblr \n",
    "There are two fundamental truths in this world: Paul Ryan desperately wants to be president. And Paul Ryan will never be president. Today proved it. \n",
    "In a particularly staggering example of political cowardice, Paul Ryan re-re-re-reversed course and announced that he was back on the Trump Train after all. This was an aboutface from where he was a few weeks ago. He had previously declared he would not be supporting or defending Trump after a tape was made public in which Trump bragged about assaulting women. Suddenly, Ryan was appearing at a pro-Trump rally and boldly declaring that he already sent in his vote to make him President of the United States. It was a surreal moment. The figurehead of the Republican Party dosed himself in gasoline, got up on a stage on a chilly afternoon in Wisconsin, and lit a match. . @SpeakerRyan says he voted for @realDonaldTrump : “Republicans, it is time to come home” https://t.co/VyTT49YvoE pic.twitter.com/wCvSCg4a5I \n",
    "— ABC News Politics (@ABCPolitics) November 5, 2016 \n",
    "The Democratic Party couldn’t have asked for a better moment of film. Ryan’s chances of ever becoming president went down to zero in an instant. In the wreckage Trump is to leave behind in his wake, those who cravenly backed his campaign will not recover. If Ryan’s career manages to limp all the way to 2020, then the DNC will have this tape locked and loaded to be used in every ad until Election Day. \n",
    "The ringing endorsement of the man he clearly hates on a personal level speaks volumes about his own spinelessness. Ryan has postured himself as a “principled” conservative, and one uncomfortable with Trump’s unapologetic bigotry and sexism. However, when push came to shove, Paul Ryan – like many of his colleagues – turned into a sniveling appeaser. After all his lofty tak about conviction, his principles were a house of cards and collapsed with the slightest breeze. \n",
    "What’s especially bizarre is how close Ryan came to making it through unscathed. For months the Speaker of the House refused to comment on Trump at all. His strategy seemed to be to keep his head down, pretend Trump didn’t exist, and hope that nobody remembered what happened in 2016. Now, just days away from the election, he screwed it all up. \n",
    "If 2016’s very ugly election has done any good it’s by exposing the utter cowardice of the Republicans who once feigned moral courage. A reality television star spit on them, hijacked their party, insulted their wives, and got every last one of them to kneel before him. What a turn of events. \n",
    "Featured image via Twitter\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google Pinterest Digg Linkedin Reddit Stumbleupon Print Delicious Pocket Tumblr \\nThere are two fundamental truths in this world: Paul Ryan desperately wants to be president. And Paul Ryan will never be president. Today proved it. \\nIn a particularly staggering example of political cowardice, Paul Ryan re-re-re-reversed course and announced that he was back on the Trump Train after all. This was an aboutface from where he was a few weeks ago. He had previously declared he would not be supporting or defending Trump after a tape was made public in which Trump bragged about assaulting women. Suddenly, Ryan was appearing at a pro-Trump rally and boldly declaring that he already sent in his vote to make him President of the United States. It was a surreal moment. The figurehead of the Republican Party dosed himself in gasoline, got up on a stage on a chilly afternoon in Wisconsin, and lit a match. . @SpeakerRyan says he voted for @realDonaldTrump : “Republicans, it is time to come home” https://t.co/VyTT49YvoE pic.twitter.com/wCvSCg4a5I \\n— ABC News Politics (@ABCPolitics) November 5, 2016 \\nThe Democratic Party couldn’t have asked for a better moment of film. Ryan’s chances of ever becoming president went down to zero in an instant. In the wreckage Trump is to leave behind in his wake, those who cravenly backed his campaign will not recover. If Ryan’s career manages to limp all the way to 2020, then the DNC will have this tape locked and loaded to be used in every ad until Election Day. \\nThe ringing endorsement of the man he clearly hates on a personal level speaks volumes about his own spinelessness. Ryan has postured himself as a “principled” conservative, and one uncomfortable with Trump’s unapologetic bigotry and sexism. However, when push came to shove, Paul Ryan – like many of his colleagues – turned into a sniveling appeaser. After all his lofty tak about conviction, his principles were a house of cards and collapsed with the slightest breeze. \\nWhat’s especially bizarre is how close Ryan came to making it through unscathed. For months the Speaker of the House refused to comment on Trump at all. His strategy seemed to be to keep his head down, pretend Trump didn’t exist, and hope that nobody remembered what happened in 2016. Now, just days away from the election, he screwed it all up. \\nIf 2016’s very ugly election has done any good it’s by exposing the utter cowardice of the Republicans who once feigned moral courage. A reality television star spit on them, hijacked their party, insulted their wives, and got every last one of them to kneel before him. What a turn of events. \\nFeatured image via Twitter'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(real)\n",
    "\n",
    "prediction = tokenizer.word_index\n",
    "num_words = min(MAX_NUM_WORDS, 500) + 1\n",
    "inputdata = pad_sequences(sequences, \n",
    "                     maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                     padding='pre', \n",
    "                     truncating='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict( np.array( [inputdata[1502],] )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 36, 37, 3, 38, 75, 76, 7, 10, 39, 6, 5, 18, 77, 4, 12, 78, 40, 41, 79, 19, 6, 42, 80, 20, 21, 22, 43, 81, 11, 82, 83, 7, 10, 5, 84, 2, 85, 4, 12, 44, 86, 15, 5, 87, 45, 88, 8, 41, 89, 5, 10, 5, 18, 90, 2, 13, 23, 1, 91, 3, 8, 92, 3, 46, 93, 14, 44, 4, 94, 95, 5, 96, 2, 97, 1, 98, 99, 24, 47, 25, 100, 101, 9, 48, 102, 49, 103, 104, 2, 105, 1, 106, 50, 7, 26, 107, 108, 9, 109, 110, 2, 1, 51, 9, 111, 112, 52, 53, 113, 114, 3, 1, 19, 6, 1, 27, 28, 115, 13, 4, 116, 117, 118, 4, 54, 119, 1, 52, 120, 29, 39, 16, 121, 24, 122, 17, 55, 123, 48, 56, 124, 7, 22, 43, 11, 15, 17, 57, 58, 3, 125, 126, 30, 56, 16, 10, 2, 31, 127, 128, 59, 60, 129, 61, 130, 131, 62, 132, 29, 8, 51, 9, 7, 32, 63, 64, 133, 134, 57, 58, 26, 30, 135, 16, 136, 65, 25, 137, 138, 42, 139, 2, 140, 61, 26, 141, 142, 49, 143, 1, 144, 145, 1, 146, 147, 35, 36, 21, 148, 1, 11, 149, 150, 151, 1, 66, 2, 13, 9, 152, 153, 1, 154, 37, 3, 38, 14, 155, 156, 157, 158, 159, 160, 161, 162, 16, 4, 12, 14, 46, 24, 163, 164, 21, 67, 30, 33, 165, 4, 1, 11, 7, 166, 167, 23, 8, 168, 169, 170, 50, 171, 65, 25, 172, 173, 1, 27, 28, 68, 174, 14, 69, 2, 175, 176, 177, 6, 178, 15, 179, 2, 47, 180, 9, 181, 182, 183, 18, 184, 2, 185, 1, 186, 187, 188, 14, 70, 20, 189, 4, 8, 190, 191, 7, 192, 193, 19, 6, 1, 27, 28, 32, 33, 194, 8, 70, 195, 196, 2, 12, 15, 197, 8, 198, 199, 34, 5, 200, 6, 54, 201, 3, 1, 20, 202, 4, 12, 22, 1, 11, 203, 1, 66, 5, 10, 5, 32, 204, 2, 62, 205, 23, 1, 11, 206, 67, 53, 33, 59, 3, 60, 63, 64, 4, 69, 207, 6, 68, 55, 71, 208, 209, 72, 29, 1, 210, 45, 2, 211, 212, 213, 214, 215, 216, 217, 218, 17, 1, 219, 6, 31, 220, 221, 72, 34, 5, 10, 222, 71, 223, 224, 1, 73, 3, 13, 31, 225, 226, 17, 227, 228, 3, 229, 230, 3, 74, 231, 232, 3, 233, 9, 74, 234, 235, 2, 1, 73, 3, 13, 4, 40, 236, 3, 237, 34]\n",
      "[35, 36, 37, 3, 38, 75, 76, 7, 10, 39, 6, 5, 18, 77, 4, 12, 78, 40, 41, 79, 19, 6, 42, 80, 20, 21, 22, 43, 81, 11, 82, 83, 7, 10, 5, 84, 2, 85, 4, 12, 44, 86, 15, 5, 87, 45, 88, 8, 41, 89, 5, 10, 5, 18, 90, 2, 13, 23, 1, 91, 3, 8, 92, 3, 46, 93, 14, 44, 4, 94, 95, 5, 96, 2, 97, 1, 98, 99, 24, 47, 25, 100, 101, 9, 48, 102, 49, 103, 104, 2, 105, 1, 106, 50, 7, 26, 107, 108, 9, 109, 110, 2, 1, 51, 9, 111, 112, 52, 53, 113, 114, 3, 1, 19, 6, 1, 27, 28, 115, 13, 4, 116, 117, 118, 4, 54, 119, 1, 52, 120, 29, 39, 16, 121, 24, 122, 17, 55, 123, 48, 56, 124, 7, 22, 43, 11, 15, 17, 57, 58, 3, 125, 126, 30, 56, 16, 10, 2, 31, 127, 128, 59, 60, 129, 61, 130, 131, 62, 132, 29, 8, 51, 9, 7, 32, 63, 64, 133, 134, 57, 58, 26, 30, 135, 16, 136, 65, 25, 137, 138, 42, 139, 2, 140, 61, 26, 141, 142, 49, 143, 1, 144, 145, 1, 146, 147, 35, 36, 21, 148, 1, 11, 149, 150, 151, 1, 66, 2, 13, 9, 152, 153, 1, 154, 37, 3, 38, 14, 155, 156, 157, 158, 159, 160, 161, 162, 16, 4, 12, 14, 46, 24, 163, 164, 21, 67, 30, 33, 165, 4, 1, 11, 7, 166, 167, 23, 8, 168, 169, 170, 50, 171, 65, 25, 172, 173, 1, 27, 28, 68, 174, 14, 69, 2, 175, 176, 177, 6, 178, 15, 179, 2, 47, 180, 9, 181, 182, 183, 18, 184, 2, 185, 1, 186, 187, 188, 14, 70, 20, 189, 4, 8, 190, 191, 7, 192, 193, 19, 6, 1, 27, 28, 32, 33, 194, 8, 70, 195, 196, 2, 12, 15, 197, 8, 198, 199, 34, 5, 200, 6, 54, 201, 3, 1, 20, 202, 4, 12, 22, 1, 11, 203, 1, 66, 5, 10, 5, 32, 204, 2, 62, 205, 23, 1, 11, 206, 67, 53, 33, 59, 3, 60, 63, 64, 4, 69, 207, 6, 68, 55, 71, 208, 209, 72, 29, 1, 210, 45, 2, 211, 212, 213, 214, 215, 216, 217, 218, 17, 1, 219, 6, 31, 220, 221, 72, 34, 5, 10, 222, 71, 223, 224, 1, 73, 3, 13, 31, 225, 226, 17, 227, 228, 3, 229, 230, 3, 74, 231, 232, 3, 233, 9, 74, 234, 235, 2, 1, 73, 3, 13, 4, 40, 236, 3, 237, 34]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer()\n",
    "# train tokenizer\n",
    "tok.fit_on_texts([real]) \n",
    "# print sequences\n",
    "ughdata = tok.texts_to_sequences([real])[0]\n",
    "print(tok.texts_to_sequences([real])[0]) \n",
    "print(tok.texts_to_sequences([real])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35,\n",
       " 36,\n",
       " 37,\n",
       " 3,\n",
       " 38,\n",
       " 75,\n",
       " 76,\n",
       " 7,\n",
       " 10,\n",
       " 39,\n",
       " 6,\n",
       " 5,\n",
       " 18,\n",
       " 77,\n",
       " 4,\n",
       " 12,\n",
       " 78,\n",
       " 40,\n",
       " 41,\n",
       " 79,\n",
       " 19,\n",
       " 6,\n",
       " 42,\n",
       " 80,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 43,\n",
       " 81,\n",
       " 11,\n",
       " 82,\n",
       " 83,\n",
       " 7,\n",
       " 10,\n",
       " 5,\n",
       " 84,\n",
       " 2,\n",
       " 85,\n",
       " 4,\n",
       " 12,\n",
       " 44,\n",
       " 86,\n",
       " 15,\n",
       " 5,\n",
       " 87,\n",
       " 45,\n",
       " 88,\n",
       " 8,\n",
       " 41,\n",
       " 89,\n",
       " 5,\n",
       " 10,\n",
       " 5,\n",
       " 18,\n",
       " 90,\n",
       " 2,\n",
       " 13,\n",
       " 23,\n",
       " 1,\n",
       " 91,\n",
       " 3,\n",
       " 8,\n",
       " 92,\n",
       " 3,\n",
       " 46,\n",
       " 93,\n",
       " 14,\n",
       " 44,\n",
       " 4,\n",
       " 94,\n",
       " 95,\n",
       " 5,\n",
       " 96,\n",
       " 2,\n",
       " 97,\n",
       " 1,\n",
       " 98,\n",
       " 99,\n",
       " 24,\n",
       " 47,\n",
       " 25,\n",
       " 100,\n",
       " 101,\n",
       " 9,\n",
       " 48,\n",
       " 102,\n",
       " 49,\n",
       " 103,\n",
       " 104,\n",
       " 2,\n",
       " 105,\n",
       " 1,\n",
       " 106,\n",
       " 50,\n",
       " 7,\n",
       " 26,\n",
       " 107,\n",
       " 108,\n",
       " 9,\n",
       " 109,\n",
       " 110,\n",
       " 2,\n",
       " 1,\n",
       " 51,\n",
       " 9,\n",
       " 111,\n",
       " 112,\n",
       " 52,\n",
       " 53,\n",
       " 113,\n",
       " 114,\n",
       " 3,\n",
       " 1,\n",
       " 19,\n",
       " 6,\n",
       " 1,\n",
       " 27,\n",
       " 28,\n",
       " 115,\n",
       " 13,\n",
       " 4,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 4,\n",
       " 54,\n",
       " 119,\n",
       " 1,\n",
       " 52,\n",
       " 120,\n",
       " 29,\n",
       " 39,\n",
       " 16,\n",
       " 121,\n",
       " 24,\n",
       " 122,\n",
       " 17,\n",
       " 55,\n",
       " 123,\n",
       " 48,\n",
       " 56,\n",
       " 124,\n",
       " 7,\n",
       " 22,\n",
       " 43,\n",
       " 11,\n",
       " 15,\n",
       " 17,\n",
       " 57,\n",
       " 58,\n",
       " 3,\n",
       " 125,\n",
       " 126,\n",
       " 30,\n",
       " 56,\n",
       " 16,\n",
       " 10,\n",
       " 2,\n",
       " 31,\n",
       " 127,\n",
       " 128,\n",
       " 59,\n",
       " 60,\n",
       " 129,\n",
       " 61,\n",
       " 130,\n",
       " 131,\n",
       " 62,\n",
       " 132,\n",
       " 29,\n",
       " 8,\n",
       " 51,\n",
       " 9,\n",
       " 7,\n",
       " 32,\n",
       " 63,\n",
       " 64,\n",
       " 133,\n",
       " 134,\n",
       " 57,\n",
       " 58,\n",
       " 26,\n",
       " 30,\n",
       " 135,\n",
       " 16,\n",
       " 136,\n",
       " 65,\n",
       " 25,\n",
       " 137,\n",
       " 138,\n",
       " 42,\n",
       " 139,\n",
       " 2,\n",
       " 140,\n",
       " 61,\n",
       " 26,\n",
       " 141,\n",
       " 142,\n",
       " 49,\n",
       " 143,\n",
       " 1,\n",
       " 144,\n",
       " 145,\n",
       " 1,\n",
       " 146,\n",
       " 147,\n",
       " 35,\n",
       " 36,\n",
       " 21,\n",
       " 148,\n",
       " 1,\n",
       " 11,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 1,\n",
       " 66,\n",
       " 2,\n",
       " 13,\n",
       " 9,\n",
       " 152,\n",
       " 153,\n",
       " 1,\n",
       " 154,\n",
       " 37,\n",
       " 3,\n",
       " 38,\n",
       " 14,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 16,\n",
       " 4,\n",
       " 12,\n",
       " 14,\n",
       " 46,\n",
       " 24,\n",
       " 163,\n",
       " 164,\n",
       " 21,\n",
       " 67,\n",
       " 30,\n",
       " 33,\n",
       " 165,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 7,\n",
       " 166,\n",
       " 167,\n",
       " 23,\n",
       " 8,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 50,\n",
       " 171,\n",
       " 65,\n",
       " 25,\n",
       " 172,\n",
       " 173,\n",
       " 1,\n",
       " 27,\n",
       " 28,\n",
       " 68,\n",
       " 174,\n",
       " 14,\n",
       " 69,\n",
       " 2,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 6,\n",
       " 178,\n",
       " 15,\n",
       " 179,\n",
       " 2,\n",
       " 47,\n",
       " 180,\n",
       " 9,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 18,\n",
       " 184,\n",
       " 2,\n",
       " 185,\n",
       " 1,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 14,\n",
       " 70,\n",
       " 20,\n",
       " 189,\n",
       " 4,\n",
       " 8,\n",
       " 190,\n",
       " 191,\n",
       " 7,\n",
       " 192,\n",
       " 193,\n",
       " 19,\n",
       " 6,\n",
       " 1,\n",
       " 27,\n",
       " 28,\n",
       " 32,\n",
       " 33,\n",
       " 194,\n",
       " 8,\n",
       " 70,\n",
       " 195,\n",
       " 196,\n",
       " 2,\n",
       " 12,\n",
       " 15,\n",
       " 197,\n",
       " 8,\n",
       " 198,\n",
       " 199,\n",
       " 34,\n",
       " 5,\n",
       " 200,\n",
       " 6,\n",
       " 54,\n",
       " 201,\n",
       " 3,\n",
       " 1,\n",
       " 20,\n",
       " 202,\n",
       " 4,\n",
       " 12,\n",
       " 22,\n",
       " 1,\n",
       " 11,\n",
       " 203,\n",
       " 1,\n",
       " 66,\n",
       " 5,\n",
       " 10,\n",
       " 5,\n",
       " 32,\n",
       " 204,\n",
       " 2,\n",
       " 62,\n",
       " 205,\n",
       " 23,\n",
       " 1,\n",
       " 11,\n",
       " 206,\n",
       " 67,\n",
       " 53,\n",
       " 33,\n",
       " 59,\n",
       " 3,\n",
       " 60,\n",
       " 63,\n",
       " 64,\n",
       " 4,\n",
       " 69,\n",
       " 207,\n",
       " 6,\n",
       " 68,\n",
       " 55,\n",
       " 71,\n",
       " 208,\n",
       " 209,\n",
       " 72,\n",
       " 29,\n",
       " 1,\n",
       " 210,\n",
       " 45,\n",
       " 2,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 17,\n",
       " 1,\n",
       " 219,\n",
       " 6,\n",
       " 31,\n",
       " 220,\n",
       " 221,\n",
       " 72,\n",
       " 34,\n",
       " 5,\n",
       " 10,\n",
       " 222,\n",
       " 71,\n",
       " 223,\n",
       " 224,\n",
       " 1,\n",
       " 73,\n",
       " 3,\n",
       " 13,\n",
       " 31,\n",
       " 225,\n",
       " 226,\n",
       " 17,\n",
       " 227,\n",
       " 228,\n",
       " 3,\n",
       " 229,\n",
       " 230,\n",
       " 3,\n",
       " 74,\n",
       " 231,\n",
       " 232,\n",
       " 3,\n",
       " 233,\n",
       " 9,\n",
       " 74,\n",
       " 234,\n",
       " 235,\n",
       " 2,\n",
       " 1,\n",
       " 73,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 40,\n",
       " 236,\n",
       " 3,\n",
       " 237,\n",
       " 34]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ughdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range (500):\n",
    "    p = predict( np.array( [data[i],] )  )\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputdata[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0  4584 13481     5  2940  1279    25\n",
      "     1   626   483     8     5    57   247  2616  2958    10  1580  1683\n",
      "     6     1   808  3960     3     1   100    82  3831    36    24  1135\n",
      "     2   144    13     1   236     1   973 20910    24    45  3674   221\n",
      "    55   465    18   100     7    12  3305     2    17  1463    27   122\n",
      "   162  2163     9     1   301     3     5   363   105   106     2   184\n",
      "   144    13     1   236    27   314   974    49    82     4    46    47\n",
      "    20   421  2794    73  5298    58    84     4  1815    31  1225     3\n",
      "   410    28    40  2231 13482    42  2905     7   236   446   928   704\n",
      "     8  1484  2117     6    18   100     1   236     8   187   303    19\n",
      "   646    28    81     2   410  1484    47    20  8018     5   900  2250\n",
      "   704    59    16  1082    41   153   902  3413 22418    88    63  2682\n",
      "    29    12  1684    17   215  3061    48     1  1264    37    40   919\n",
      "    51     2   548   414   303  2484   103     1   236     1  3771   834\n",
      "     8   118  1370     7     1   677   244  1047   472    34   929     5\n",
      "  1696  6778    48    30   461   113    71    82     4     1  3771  3350\n",
      "     8   118  1638    19     1   153     4     1   190     2 14884   648\n",
      "   179     1   625     3     1   360     3     1    36   539     4    82\n",
      "    36     1  5870  2130   174   236  1175     4   705  3062    47    24\n",
      "  1135   168     1    57   247   231    24  1351   704     2  1480 10926\n",
      "  8286    77  4092  3811   704   600  8019   236  3091    37  5024  4947\n",
      "    58   484     7   122 20911  4864     1  2784  3135    24   814     5\n",
      "  3038   796     9  2753  4585    22     2    17    78    24    31  2959\n",
      "  1993     7     1  1448     8   242    31   303    10    43   234   928\n",
      " 20912   999    10  3503     2  4509   646     7    14    15   162  2934\n",
      "     4  5812    14  1165   704     3  7595    13   111   154     4     1\n",
      " 15456     4    38   599     1 18608   135  1047 15457    15     5  3960\n",
      "  4482   153  1102  1449   704    13  4865  5299    72    38   145  1410\n",
      "     5  8287  2859 14885  1108   296  7297    10   114  5208   861   500\n",
      "  3372  2392    24   675   704     5   900  3787    88     3  4865     1\n",
      "  3462   377     1  3462   377     8     5  2450   521     7    24    11\n",
      "   133 10019     6     1   994     3    81    11     1 10686  1444    27\n",
      "     1  3358   127  4012   982  2622    13   153  8731    25     1  7033\n",
      "   610    10     1  3462   377   187     1  2216   112  3787     1   236\n",
      "   446     3    44     3     1    92  5300 10687   103    82   348    48\n",
      "   928   704     8   242    54     2  2160    82    14  2883    44  2124\n",
      "     3     5  3556   123     2    72    12    22   215   182   374   190\n",
      "    51  8020     5 11182     3  2322    56    14   761    82    36     5\n",
      "  1147     6     5  2131   168   390    48    14   242    51    54     2\n",
      "  1837    29    19  1790     1   266  1448   113   192   139    14  6163\n",
      "     1   360    15    14    10     1  9796     3   111   154     4     1\n",
      " 15456   143   126     4  1702    12 16123    37    15    12     5  4483\n",
      "  1212   121  1883   699     4   434   720  1920    88    80   469     5\n",
      "   298    25  1973  4448  1911   522   704     8     1    92 15458   236\n",
      "   446     7   348  2370    37   450    73 17677   416     2  8439     5\n",
      "   105  3812     7    24  6095    88   174     5  3062   834   668   105\n",
      "  6710    16  2960     2  1484   575     4    23   181  2025   668 16872\n",
      "  1175    73   173     2    17   976     2    72    40   662     1    87\n",
      "  1665  5687   369     8   192    82     4    46  6225   959     2   184\n",
      "     2   144    13     5  5209   218   819    92   177    76     1   236\n",
      "   112    82    36  6855     5  1292  4904  3063     4   122    31  1912\n",
      "   332  1484   313   785    15     2  1981     4  2642     7     1   236\n",
      "    85    52     5   778   360  4225   432    46  6225  2287     7    12\n",
      "    15     5   196  1079     1   236  8440    46     4    50 10224    12\n",
      "   179    27     1   313  4905  1034    24   379   123     2     5  7207\n",
      "  1286    10     1   236  6164     7   406    15   726    15     5   589\n",
      "   785    27    12    15     5   288    44     7  4153     5   445    13\n",
      "     1   236   112 11183    36  6225   679     2   711     7     1   236\n",
      "     8   242     1 15456    59    16    93   430  7034    82    36   229\n",
      "    17 10225   354     2 12049    54    25     1   236    84     7    50\n",
      "  1157     7   575     8   712     1   163   477     3 12050     7   475\n",
      "    46     2   403    46   575 10688  3540    83   425    46     2  3414\n",
      "     5   144    10     1   236     9 22419    46   164     1   808  1613\n",
      "     3    46    70    27     1    69  2670     8     7    46    47 11184\n",
      "   113     2   144    13     1   236     8    22     1  1559     3     5\n",
      "  2207     4  1249   119    70   122    31   377     3  7596    56     5\n",
      "   119   171  4255     7    46    87  2494     8     2   679     4  1847\n",
      "     1  3350     3     1   236   314    22 12050   122   772     3    49\n",
      "     1   236   229    17    39     2  3005    39    46   164     1  1921\n",
      "   236   360    82    36    15  2555     7    50    83  4178    12    54\n",
      "     4    50    52   203   494     9  4035     7    27     7    82    36\n",
      "     8  1135     6    46   300     8     5  9197 11185   470     5   765\n",
      "  1338     3    78     1    36    70  3320     2  3876     1   142    24\n",
      "    45  4093    19     5  2873     4 15459  1054     7    24  1249    43\n",
      "    77   696    10   822     1   236   609    87    44   494     9   152\n",
      "  4092  1559     1    36    70    24   959     7    31   236   360     3\n",
      "     1   776  7485     3   271  4995     5   639     2    77  3525     4\n",
      "    55   122  1135    43     6    10   822     1   236   122    31  2163\n",
      "   950  1015     3   772   122   418     2   145   220     7   772     8\n",
      "  6296    27     1  2381     3     7   772   254  2164    68     5   682\n",
      "   326    36  7597  1762     1   313   360    30  1110     1  1522   812\n",
      "     3    78    11   141    11    30  1110     1   205   523    84  2556\n",
      "    30    16    61   759     6   315     4    30    16  2557    38    64\n",
      "  9352     1   772     1   236    24 16873    28     1   360     3     1\n",
      "    36   539   122  2217    57   271    43     1    78     4 17678 11184\n",
      "     1     3 17678    20   954     7     1   266  1448     8    73    55\n",
      "   133  3557   257   923    43   314   167     8     1  2061     3 19649\n",
      "   257   102     3     1  3877    27    18   725    90    38  5254     2\n",
      "  3557   122    90    38  1676     2     5   923     1  9353  1286    10\n",
      "     1   236  2164    68     7    82    36     4    46   919    16  2557\n",
      "     3     5  4068  1890    63     1  2275 22420     3    46   266 10456\n",
      "     1   266 10456    15     5 19650  1177    58     1    36    70    24\n",
      " 11184  3136    54     3     1  2251   135    37   726     7  1164   833\n",
      "     1   823 10456    15  1560     2  1177    58     8    25   851     3\n",
      "   118  2153     1  1264    20 20913  4482  2874    74     1   108  1164\n",
      "    30    16  2712    18    78   221     8  1890    63     1  2402  1310\n",
      " 14394  1130  6779     4  5157     3   212     7    20  1277    79   221\n",
      "  1080     1   108    18     8  1890     4    41  3706    63   102     3\n",
      "     1  1994     7    20   254   225    54     4    30   185   173   236\n",
      "  1523  2713   712    12     1    70   103   704     8  4121  5301   122\n",
      "    66     5  1651   102   709   236    47    32  1661    40  6630    16\n",
      "   118  1370     2  1048   333     1   190    16  2795  4013   221    40\n",
      "   301   103     1   236   122    31  3961     4  2163  1838    12   129\n",
      "    66    17    40   116   730    82    36    24 17677  5077    46   123\n",
      "   169  2382  2874     6    73    18   100  1764    27  1251   200  1513\n",
      "   772    37  7596   117    84     7    24  1106  1164    50     8  2557\n",
      "     3    12  1421  5158     6    46   271    13  2044  1652     4    12\n",
      "    64   747    46   159    76   406   810    24]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "#sequences = tokenizer.texts_to_sequences(real)\n",
    "print(sequences)\n",
    "#word_index = tokenizer.word_index\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "data = pad_sequences(sequences, \n",
    "                     maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                     padding='pre', \n",
    "                     truncating='pre')\n",
    "print((data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
